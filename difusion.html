<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Machine Learning - conceptos, tipos, casos de uso y algoritmos" />
    <meta name="keywords" content="Machine Learning, Aprendizaje Supervisado, No Supervisado, Refuerzo, IA" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="../css/estilo.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css" />
    <title>FAI-AI — Machine Learning</title>
</head>

<body>
    <header>
        <div class="conjunto">
            <div class="logo">
                <a href="../index.html"><img src="../Imagenes/Logo.png" alt="logo"></a>
            </div>
            <div class="titulo">
                <h1><a href="../index.html">N-AI</a></h1>
            </div>
        </div>

        <nav>
            <ul class="lista">
                <li><a class="link link--1" href="../index.html">Principal</a></li>
                <li><a class="link link--1" href="../html/ml.html">Machine Learning</a></li>
                <li><a class="link link--1" href="../html/dl.html">Deep Learning</a></li>
            </ul>
        </nav>
    </header>
    <main id="main-dl">
        <selection id="selection-cnn">
            <h2 id="modelos-h2-cnn">Difusión</h2>
            <div id="modelos-cajas-cnn">
                <p>
                    Los modelos de difusión son modelos generativos que se entrenan utilizando el proceso de difusión directa e 
                    inversa de adición progresiva de ruido y eliminación de ruido. Los modelos de difusión generan datos
                     (la mayoría de las veces imágenes) similares a los datos con los que se entrenan, pero luego sobrescriben
                      los datos utilizados para entrenarlos. Añaden gradualmente ruido gaussiano a los datos de entrenamiento
                       hasta hacerlos irreconocibles y, a continuación, aprenden un proceso de "eliminación de ruido" inverso 
                       que puede sintetizar la salida (normalmente imágenes) a partir de la entrada de ruido aleatorio.
                </p>
                <p>
                    Un modelo de difusión aprende a minimizar las diferencias de las muestras generadas frente al objetivo deseado.
                     Se cuantifica cualquier discrepancia y se actualizan los parámetros del modelo para minimizar la pérdida, 
                     entrenando al modelo para que produzca muestras muy parecidas a los datos de entrenamiento auténticos.
                </p>
                <p>
                    Más allá de la calidad de la imagen, los modelos de difusión tienen la ventaja de no requerir entrenamiento
                     de adversarios, lo que acelera el proceso de aprendizaje y también ofrece un control estricto del proceso. 
                     El entrenamiento es más estable que con las GAN y los modelos de difusión no son tan propensos al colapso de modos.
                </p>
                <p>
                    Pero, en comparación con las GAN, los modelos de difusión pueden requerir más recursos informáticos para entrenarse, 
                    incluido un mayor ajuste. IBM Research también ha descubierto que esta forma de IA generativa puede ser secuestrada 
                    con puertas traseras ocultas, lo que da a los atacantes el control sobre el proceso de creación de imágenes para que 
                    los modelos de difusión de IA puedan ser engañados para generar imágenes manipuladas.
                </p>
            </div>
        </selection>
    </main>

</body>

</html>